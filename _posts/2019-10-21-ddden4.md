---
layout: post
title: 领域驱动设计DDD入门4：上下文映射
categories: [dev]
tags: [ddd]
---

欢迎来到第四课：战略工具之上下文映射。
本课重点介绍上下文映射以及各种团队关系和集成技术，这些技术可用于管理多个有界上下文如何和谐地工作以形成整个系统解决方案。
首先，我将介绍有限上下文之间的上下文映射。这导致对各种上下文映射、团队关系和集成技术的检查，包括伙伴关系、共享内核、客户供应商、遵从者、反腐层、开放主机服务、发布语言、大泥球等。然后我们看一下如何充分利用上下文映射，我们会将上下文映射与SOAP和RPC一起使用，RESTful HTTP和消息传递。最后，我给出一个使用消息传递和REST的使用上下文映射的示例。


Again, on a DDD project, there are always multiple bounded contexts at play. At the center of our diagram, we have the agile project management context, which is our core domain. We also have various supporting and generic sub-domains involved. The question is, when we integrate our core domain with these other sub-domains, how is that integration accomplished and what are the relationships of the teams within this project? Remember that our agile project management context or our SCRUM project management service is integrating with our collaboration context in order to get support for forum discussions and calendars with calendar entries. What we're interested in is the line between the two contexts. We're interested in what that line represents.

So, what we're interested in understanding is what does the line between the two ballot contexts represent? It represents both team relationships but which relationships and which integrations exist between the two ballot contexts? What options are there? That's what we're gonna take a look at next.

The first relationship that we're going to look at is partnership. This is where two teams work on two different bounded contexts but they have common goals and they're supporting each other. Team one is in one bounded context, team two is in a different bounded context. But, because of the relationship being a partnership, this is a very heavy relationship between the two bounded contexts. That's why there's a thick line leading from one team to the other team. This is because they have to coordinate their deliveries together, they have to release at the same time, because they are supporting each other. There is no upstream downstream relationship between these two. Their models stay in sync for a considerable period of time. Therefore, it takes a lot of coordination, it takes a lot of planning. These two teams have to work carefully together to make sure that everything works out smoothly in support of each other.

A shared kernel is where at least two teams have a very similar software model. Therefore, they're going to develop a single shared portion of a model that they're both going to use. I think that this is a relatively unusual situation, because it takes a lot of planning and a lot of coordination and integration testing to make sure that both teams benefit from this small core model. It's probably unlikely that this is going to be used very often. Because it requires teams to share a lot of information and agree on how their model is going to work in conjunction together. And, because of that, it's unlikely to be able to form that level of communication and coordination between two different teams who may tend to not collaborate or communicate effectively otherwise.

A customer-supplier relationship is where there is a definite upstream, downstream relationship between two teams. As you can see by the U and the D on this diagram, Team 1 is upstream, Team 2 is downstream. Team 1 is upstream, Team 2 is downstream. This means that changes in the model for the upstream Team 1 This means that changes in the model for the upstream Team 1 will have an impact on the downstream Team 2. These changes must be coordinated through negotiation These changes must be coordinated through negotiation and other kinds of communication that Team 1 and other kinds of communication that Team 1 and Team 2 need to have together. Team 2 will actually request certain features in their model that Team 1 is developing and this coordination will have to be met by Team 1 and this coordination will have to be met by Team 1 so that Team 2 can get the features or functionality that they need, but it's really up to Team 1 to satisfy Team 2. If that doesn't occur, then Team 2 won't get what they need in the time frame that they need it and so it can have a very negative impact on Team 2. It's also possible that Team 1 could make changes to Team 2 to the model that Team 2 is going to consume and because of those changes it could have a negative impact on the delivery that Team 2 will be able to make.

A conformist relationship is where there is a definite upstream downstream relationship where Team 1 has an upstream model that will directly impact and influence the downstream Team 2 model. In fact, Team 2 will just basically slavishly consume the model of Team 1 and conform to it. Because it's such a complex model and a big model, that Team 2 really doesn't have the time or resources to make modifications. So they will simply consume it as if it is part of their own model. That's the conformist.

Anti-corruption layer is where there are two teams with two separate models, but the downstream team does not want to be influenced by the upstream model unnecessarily. Therefore, it's the opposite of the conformist pattern. The upstream team has its own model, but the downstream team will consume that model and translate data and other structure of the upstream model into its own structure and data in the downstream domain model, or bounded context. The downstream team is refusing is be influenced by the upstream team except in the ways that it needs to be influenced or to consume data and structure. That's why in this diagram, the structure of the upstream Team 1 model is completely different from the downstream Team 2 model. And as you can see, there is the ACL, or anti-corruption layer, translation layer, between the model of Team 2 and the model of Team 1.

An open host service is a well documented, well defined, and convenient and nice model to consume. This is where team one has produced a very good API. Perhaps it's a restful API. Perhaps it's a messaging API. Perhaps it's an RPC API. Whatever the case, it's well documented, and it's a pleasure to integrate with. Team two therefore uses the open host service directly and can consume the model as it is or translate it easily because it is an open host service that's easy to translate.

A published language is where the upstream team one produces a well defined, well documented data exchange format that allows team two to very comfortably and conveniently consume data from team one. It's very common for an open host service to also provide a published language to the downstream teams. Therefore it makes it very convenient to consume the data and the structure from the opposite model, and the downstream team two can easily translate it in and out of the standard format.

Separate ways describes the kind of integration that could take place between Team 1 and Team 2. For whatever reason, perhaps expense, perhaps lack of convenience, perhaps it's because of the low benefit of consuming Team 1's model, Team 2 decides to go separate ways. And create a one-off solution within its own model to the solution that they need and could've consumed from Team 1. But they simplify things and simply go a separate direction from how they could've used the integration with Team 1.

We've already talked about a big ball of mud. Of course, you want to steer away from developing a big ball of mud as much as possible by using the DDD strategic tools. However, you will likely have to integrate with a big ball of mud at some point. Now, another warning about the big ball of mud and developing a big ball of mud is this. When you make changes in one part of the model, it will very likely have a negative impact on another part of the model. Where you have changes that ripple and you end up with whackable issues is where one change has a negative impact on the data or the model in another area, and you try to stomp out that situation, and when you change that, then this changes ripples to another area. The big ball of mud is actually a very negative situation to be in as far as a domain model. So you should steer against it. If you do have to integrate with a big ball of mud, try to use an anti-corruption layer between your downstream bound of context, which is no doubt a clean core domain, and the upstream big ball of mud. This will allow you to consume the big ball of mud on your terms and make its data and structure adhere to your data and structure in your model in the downstream.

How will you actually use context mapping for integration between bounded contexts? While we're going to discuss now three different integration styles and how these can be used with context mapping, we're going to discuss RPC, or remote procedure calls, we're going to discuss RESTful integrations, and we're going to discuss messaging.

First of all, let's discuss RPC with SOAP. This is where we have a Service Bounded Context and a Client Bounded Context; The Client Bounded Context must look up a service in a service registry and that service will be used in the Service Bounded Context and consumed by the client; the disadvantage with using RPC is that RPC can fail, because of network situations, perhaps in network partition or other situations such as bandwidth, some sort of interruption in network connections; they're all kinds of things that can happen with RPC and so, the disadvantages that a client who depends on an RPC integration with the Service Bounded Context may be unable to complete its integration in real time, which can cause failure. But, when RPC works and RPC mostly works, it can be a very desirable and convenient way to implement an integration. The Service Bounded Context will likely benefit from being designed as an Open Host Service with a published language and with downstream consuming Bounded Context can use an empty corruption layer in order to translate and use the upstream model only on its own terms, such that the Client Bounded Context will have its own unique model, its own unique data instructure and it does so by translating from the upstream Open Host Service and published language into its own unique model composition.

RESTful HTTP is much like RPC in that a client bounded context must communicate with a service bounded context through a network connection. The common verbs used in a restful integration are post, get, put and delete. These are provided by the service bounded context. And the client bounded context uses these verbs to accomplish certain goals within the integration of the service bounded context. These are are the RESTful HTTP requests. Again, when integrating a service bounded context with a client bounded context you're going to exchange data quite likely using a document format of some kind. These are the RESTful representations that are exchanged between the two bounded contexts. Typically you will want to again create an open host service with a published language on the service bounded context. The published language is actually the representations that are exchanged between the two contexts. The client bounded context would also likely benefit if it had an anti-corruption layer that translates the representations that are provided by the service bounded context into it's own local model. Just be aware that with this sort of integration, you will also likely face at some time problems with the network in the same way that hinders this integration when using RPC, rest integrations will have to be handled in much the same way with potential network failure. And that's what we see here where there is a disconnect between the client bounded context and the service bounded context. When designing resources for your service bounded context your published language, you should design the resources according to the use cases that your client wants to consume. If you have multiple clients, you'll want them each to have the opportunity to consume your resources on their terms. This will prevent the service bounded context from forcing each client to have a conformist relationship with the service bounded context. You would force your consumers into a conformist relationship if you designed your resources according to your own internal domain model. Don't do that. You'll make your clients much happier if you listen to their needs and allow them to consume your resources according to their own use case requirements.

As you've seen with RPC and RESTful integrations, the network can cause problems for this kind of integration. We're going to now look at a more robust form of integration, that of using messaging. Messaging with DDD oftentimes uses domain events for the integration. This is where an aggregate and domain events are published by aggregates and consumed by other bounded contexts. This is through a messaging mechanism. And there are a lot of different options for using messaging mechanisms. So the main pattern is where an aggregate will publish a domain event, and that aggregate, in publishing the domain event, makes the domain event available for another bounded context and the other bounded context, the subscribing bounded context, will get the domain event from the publishing bounded context, and this domain event will likely have an impact on another aggregate in the subscribing bounded context. Sometimes, you must provide a command to the service bounded context in order to get it to do something to cause a domain event to occur so that the domain event can have an impact on the consuming, or client bounded, context. When you use domain events with a messaging mechanism, you must support at-least-once delivery and your receiver, or subscribing bounded context, must be an idempotent receiver. What I mean by that is the messaging mechanism that you choose must support at-least-once delivery. That means that the message will be delivered at least once. Because the message can be delivered at least once, the subscribing bounded context must be idempotent, or have the ability to, in essence, de-duplicate or consume without negative consequence, a redelivered domain event message. Here's what I mean by that. If a messaging mechanism delivers a message, it may be that before the acknowledgement of the receiver that it has received the message to the messaging mechanism, can cause the same message to be delivered more than once. Here you see the message being delivered twice and in this case only one acknowledgement is provided. Therefore, because the messaging mechanism can cause the message to be delivered more than once, the receiver must be an idempotent receiver, like you see here. Let's say that the message that is delivered by the messaging mechanism is the message to open some sort of resource. If that message is delivered twice, or three times, or more, the receiver must be able to react responsibly to that multiple reception and cause the resource to only actually be opened once, not multiple times. This can be accomplished by de-duplicating the message within the receiver. It can also be caused, or be handled by some form of keeping the state of the resource, such as the status, already being open. That will prevent the open of the resource multiple times.

Let's go through an example of integrating using messaging what we're going to do is go back to our example of policy within three different bounded contexts. We have our insurance, industry example, we have an underwriting context, a claims context and an inspections context. We're going to look at how to integrate these bounded contexts by means of messaging with domain events. Let's say that a policy first becomes created and alive within the underwriting context. Underwriting is generally where the insurance company will make an agreement with a customer to insure them and the policy at that point becomes existing. Now, insurance terms it's probably the case that this policy will be deemed issued so the domain event that's going to be published by the underwriting context is the policy issued domain event. When the policy issued domain event is published by the underwriting context it can now be consumed by the claims context and the inspections context. When this happens, it can cause the creation of policies in the other two bounded contexts. In other words, the claims context will create a policy of its own type within its own bounded context in reaction to the policy issued domain event. And the policy issued domain event will also cause the creation of a policy in the inspections context according to the terms of inspections and therefore we now have three separate policies. One that was originally created in the underwriting context and the other two that were created in reaction to the policy issued domain event. In the underwriting context, we have created our policy and created the policy issued domain event which causes in the subscribing bounded context a policy to be created. Now, how much data does the policy issued domain event hold? It should be somewhat limited, we don't want to necessarily publish a domain event that has all of the state of the policy from the underwriting context. It should just have enough state to convey the fact that the policy has been issued and allow that policy to be reacted to in other bounded contexts. But it could be that one of our subscribing bounded contexts needs more data from the underwriting context. What can we do? Well we can actually allow our subscribing context to query back on the underwriting context using the policy ID of the policy that was issued in the underwriting context to allow it to query the data that it specifically needs in the subscribing bounded context. Notice in the subscribing bounded context that policy in that context holds the original policy ID from the underwriting context under the name of issued policy ID. This refers back to the exact identity of the policy entity in the underwriting context which allows us to perform a specific kind of query. The underwriting context can then implement an open host service with a published language and the subscribing bounded context can use a restful GET request to get more policy data from the underwriting context. As you can see there it does a GET verb in a restful way slash policy slash issued policy ID. And from this it receives data in the form of a published language, thus, the underwriting context publishes its policy issued domain event with a policy ID and that policy ID can be used to consume other information from the underwriting context. What about the example that we had before with the agile project management context and its surrounding, supporting and generic sub-domains, don't worry, we'll return to that example next.

[Instructor] In summary, in this lesson you learned about the various kinds of context mapping relationships such as the partner relationship, the consumer-supplier relationship, and anticorruption layer. You also learned how to use context mapping and integration with RPC, with RESTful HTTP, and with messaging. You learned how domain events work and how to use them in a messaging environment, and you learned the foundation on which you can build your context mapping experience.

