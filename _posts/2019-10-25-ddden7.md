---
layout: post
title: 领域驱动设计DDD入门7：加速工具和管理工具
categories: [dev]
tags: [ddd]
---
这是本系列最后一课：加速和管理工具。如何加速DDD建模并在项目中应用？如何在敏捷项目中使用DDD？我将在这堂课中讲解。我会先讲事件风暴方法，可以快速建模和获取知识。然后讲敏捷先如何使用DDD，会附带一些额外的工具。后面我会教你如何标识任务和估时。最后说一下时间盒模型。

当使用DDD时是在获取知识，我们在学习业务。我们需要根据业务知识进行高效建模，以便把我们的业务优越性也体现在软件优越上。所以是尝试的问题：通过挑战我们的模型，反复尝试，钻研业务知识，形成更好的模型。而对于我们快速迭代的公司，要求野蛮生长，反而是时间的问题。我们总是“活”在项目deadline的边缘，不断被催促。怎么才能协调高效建模和快速实现的矛盾呢？假如我们设计得很好，实现得很漂亮，但是逾期交付了，那也是项目失败了！我们该怎么办？
这里介绍一些加速工具和管理工具，这些工具有助于在项目中实践DDD并符合项目工期约束。多说一句，有些人尝试了一种称为“无估计”的技术，这种技术轻视任何类型的评估，这些评估可能几天或几周或几个月甚至一天，团队会尽量避免做出估计，因为他们说这些估计不准确。
我认为与我合作的大多数客户都是不可接受无估计方案的，他们大多数仍处于时间约束，非常严格的时间约束之下，他们需要提供估时。这该怎么办？我们被要求必须估时，而估时既耗费时间又不准确。这里也提供一种方法来跟踪您的时间和领域专家的时间，并准确估算实现高效模型各个组件所需的时间。因此，我们必须在时间约束内建模。我们的目标是了解业务和领域并进行有效建模，并不断完善模型。我们需要花费时间去掌握业务知识，但如果我们不快速学习和建模，即使有良好的产出，我们也是失败。我们必须限定建模工作的时间，但绝不能尝试以任何方式消除设计，因为如我们先前所讲的，没有设计就是谬论。那么当我们面对时间挑战，我们该怎么做？我们将使用一些建模加速和管理工具，比如事件风暴和敏捷估算。这里讲的技术将可以与任何敏捷框架一起使用。

# 事件风暴

事件风暴是一种加速建模和获取知识的技术。使用事件风暴，我们要做的是专注于业务流程，而不是数据、数据库或数据模型。我们的首要重点是业务流程中的操作，我们会将其建模为领域事件。我们还将对域事件的起因（即命令）进行建模。我们还将对聚合或实体建模，如果愿意的话，命令将在其上发生并导致发出域事件。使用事件风暴时，团队中的每个人，领域专家和开发人员，都在一起学习，会互相学到很多东西。这是一种非常快速的建模方法，并且很有效。每个人总是从经验中学习。开事件风暴会议时最重要的事是合适的人员。应该始终拥有整个领域专家团队或至少一个领域专家，以及开发人员，永远不应将专家排除在外。
基本上，事件风暴与询问正确的问题有很大关系，正确的问题只能由正确的人提出，并且由正确的人回答。这也是为什么始终让领域专家参加事件讨论会议。团队中的每个人都能学到东西。
<div align="center">
<img width="80%" src="/images/post/ddden13.png">
</div>

## 事件风暴会议

首先，我们需要便签纸。这里有一系列便笺，主要用于事件。事件将在橙色贴纸上建模，命令将在蓝色便笺纸上建模，聚合或实体将在淡黄色上建模。可能还有其他种类的便利贴，例如红色记录在建模会议中可能需要注意的警告或错误，绿色用于建模用户接口组件或视图，淡紫色或紫色对模型中发生的策略或过程进行建模，黄色记录用户规则或角色。也可能还需要更多种类的便贴，例如白色等等，但这些可能是您需要的少数。另外建议使用合适的笔，太大的笔在便签上写不了太多东西。

我们还需要一个好的建平面，比如一张宽大的纸，最小也得10米（what？...）。实际上，我们希望建模平面是无限的呢，所以多拿几张大纸。当然可以尝试在墙壁或白板上进行建模，但是我发现便签纸在白板或墙壁上不太能粘住，在纸上效果更好。你可以去艺术品商店，或五金商店或类似的商店购买，宜家一般也有这种纸（国内的好像没有...逃..）。拿一卷纸，用厚胶带粘在墙上，这就是我们的主要建模平面。
我们的建模元素是便：橙色便笺纸为事件模型，蓝色便笺纸为命令，黄色便笺纸为聚合。这些是我们的三种基本建模元素。同样，策略或流程以淡紫色或紫色的粘滞便笺为模型，绿色用于用户接口视图，用户角色以黄色建模。

### 第一步：按照时间顺序建模事件

第一步，团队中的某人需要拿橙色便签，并在上面写一个事件。这是一个事实：域模型中发生了某些事情。将该事实命名为过去时的动词。例如我们之前所讨论的，productCreated 或backlogitemCommitted，事件就这样命名。这个事件不一定是要建模的核心域中可能发生的第一个事件，可以选择在业务流程中间发生的事件。重要的是要使第一个事件出现在建模平面上。
<div align="center">
<img width="80%" src="/images/post/ddden14.png">
</div>
它提供了一个开始建模的地方，并且提供了一个提出有关问题并获得正确答案的活动。你将按时间顺序从左到右构建一系列域事件。如你所见，箭头显示了穿过整个业务流程模型的时间。最早发生的事件在最左边，然后随着时间的推移，下一个事件发生，下一个，下一个以及最后到最右边，最右边是业务流程中发生的最终领域事件。

这是第一步，可能需要一些时间。可能要花一两个小时来处理所有域事件。如果感到疲倦，或者团队中的每个人都开始对流程失去热情，那么该休息一下了。暂停会议几个小时甚至一天。如有可能就睡在大纸上（what，这就是要10米大纸的原因吗...），第二天继续会议，可能就会发现很多在第一次开会中遇到的问题，第二天将能够取得更好的进步。

### 第二步：给引起事件的命令建模

下一步是对导致域事件的命令进行建模。同样注意，我们要有意远离数据。在此过程中，我们并不是最先关注聚合或实体。你可能发现单个命令实际上会导致多个域事件，可能还会发现某些命令导致域事件并行发生。如果是这样，并且只有在开始对命令进行建模时才发现是这样，可以垂直表示发生的并行事件。因此，并行发生的事件是使用垂直空间而不是水平空间，上下并列就表示某些事情同时发生。
<div align="center">
<img width="80%" src="/images/post/ddden15.png">
</div>
现在我们正在建立时间轴，并且有一系列有时序的命令和事件、命令和事件、命令和事件。第一条命令在建模平面的最左侧，而最后一条命令和事件在最右侧。

### 第三步：对聚合进行建模

领域专家可能对聚合一词不满意，你可以将其称为模型的实体，或者可以称为模型的数据。
对于领域专家而言，了解聚合或实体具有行为并不重要，但他们可以理解数据将接收命令，处理该命令并产生域事件。因此可以将聚合叫成任何名称，只要领域专家可以理解。
<div align="center">
<img width="80%" src="/images/post/ddden16.png">
</div>
从最左边开始，我们有一个聚合或实体来处理命令并发出域事件。然后，我们有了下一个处理命令的聚合，并发出一个域事件，依此类推，直到到达图的最右边为止，那里我们有与聚合或实体相关的最终命令事件对。注意，随着时间的推移，同一聚合可能会收到不同的命令，要记得使流程保持时间顺序。
因此，不要对单个聚集或实体采取多个命令和事件，它们都要按时间顺序写在多个黄色便签上。所以如果同一聚合随时间推移收到不同的命令，那么就复制黄色便签，用相同的名称创建第二个、第三个、第四个黄色便签，然后将其移动到合适的时间序列区域。这对于使时间顺序保持正确非常重要，这样随着时间推移，模​​型中发生的事情就可以准确地表示时间。

### 第四步：确定上下文边界

在前面的建模过程中，你可能已经意识到其中一些适用于核心领域，而另一些不是。某些命令和事件将发生在属于其他有界上下文的实体上。怎么确定上下文边界呢？
尝试准确地确定什么是核心领域，什么对你们公司而言具有重要意义和竞争优势，哪些不是。无论是支持型的还是通用型的，都应移到其自己的有界上下文中。
<div align="center">
<img width="80%" src="/images/post/ddden17.png">
</div>
现在你可能需要在图上绘制显示事情发生时间的线，还需要画椭圆形标志上下文边界。可能在某种程度上需要重新排列便签，但是不想失去顺序信息。这就是事件风暴的建模从大方向转为详细设计的过程。一开始我们使用事件风暴对大局进行建模，但是随着时间的推移，建模工作会越来越深入。也许在第二或第三次建模会议之后，将开始接触越来越多的细节。这很自然但很重要，实际上就是我们想要达到的。我认为，事件风暴在设计或实现模型时非常重要。你不会学习到所有细节，正如我之前课程所描述的，这将留给创建场景和验收测试的会议，但是将了解一定程度的实现细节，这有助于我们未来的建模工作。

### 第五步：其他
可能需要了解对用户很重要的某些视图，写在绿色便签上。

另一个建模步骤是确定某些策略。执行业务策略的过程很复杂，将策略或流程标记为淡紫色或紫色表示它的复杂性，策略将接收事件并发出命令。这很典型，因为策略是对域事件做出反应并告诉其他聚合该怎么做。因此，实际上它与聚合相反，尽管它类似于聚合，但是聚合接收命令并发出事件外，策略将接收事件并发出命令。你可能还会发现，即使在第一步建模域事件中，也可能较早地确定策略。如果是样，继续前进，并确定对整个业务流程至关重要的策略。

# 敏捷框架中的DDD

Next I'm introducing you to some ways to manage using DDD in an agile execution framework. But first of all, I want to give you a reminder: reject the Task-Board Shuffle. Recall that this is where you have, for example, a Scrum board with a to-do column, an in-progress column, and a done column. And the entirety of your design efforts is lifting a sticky, such as this appointment entity, from the to-do column and placing it into the in-progress column, and we're calling it Designed. This is actually bad design, not good design. And so you want to avoid the Task-Board Shuffle entirely. Also, I want to make clear that as I describe this, the Agile Execution Framework that you can use could be Scrum, it could be Kanban, or it could be another agile approach. What I want you to understand is as I am discussing this, I will be talking mostly in terms of Scrum. But it is still particularly applicable to Kanban or any other agile process. And as I have occasion, I may call out where Kanban and Scrum differ, but how you can still apply the techniques that I am going to show you.
接下来，我介绍一些在敏捷执行框架中使用DDD进行管理的方法。首先请记住：拒绝任务板乱放。假设下面是你要使用的敏捷看板，其中包含待办事项列，进行中列和完成列。设计工作是从待办事项列中删除一个对象（例如appointment实体），并将其放入正在进行的列中，我们称其为“设计”。这实际上是不好的设计。
<div align="center">
<img width="80%" src="/images/post/ddden71.png">
</div>
> 在我进行讨论时，我将主要就Scrum进行讨论。但是它仍然特别适用于看板或任何其他敏捷过程。有时，我可能会指出看板和Scrum的不同之处，但是您仍然可以用我将要展示的技术

Before we get in to the actual use of the agile execution framework what I want to do is show you that there are other tools that can be applied when you're using DDD on an agile project. One of these is a SWOT analysis diagram or modeling surface. This is where you create four quadrants. You create the strengths quadrant, the weaknesses quadrant, the opportunities quadrant and the threats quadrant. This is where SWOT analysis gets its name. You may have used this before. It's not a new technique. But it can be handy in identifying strengths and weaknesses, opportunities and threats. So in the strengths quadrant identify what's going good for you, what's working out well. In the weaknesses quadrant identify anything that needs to be improved. In the opportunities quadrant identify where you need to focus your energy. In the threats quadrant write down the obstacles that must be surpassed and if not you're going to face real problems. This can help you to know even where your event storming efforts need to focus, where your acceptance tests need to be designed and where you need time with domain experts. The bottom line, what we're trying to accomplish with SWOT analysis or any other tool is to identify any knowledge gaps that we have in the model. So whether or not you use SWOT analysis find where your modeling needs work. Identify that and use whatever tool you need both to identify it and to accomplish a good outcome. Knowledge acquisition and crunching knowledge will lead to modeling breakthroughs. And this is especially so if you use event storming.

Does it surprise you that there will be modeling spikes and modeling debt in a DDD project? Here's the thing, I think that you will face modeling spikes and modeling debt and I like this terminology because it fits in well with agile execution frameworks, especially Scrum. But it can also be used with Kanban. Here's the point. You will likely have a modeling spike during project inception and this is where you can use event storming during the spike because you're going to spend perhaps a few hours for two or three days in order to address the modeling spikes. You will then take the results of the event storming sessions and experiment with your domain model. Write acceptance tests and flush out the model against the acceptance tests and this will help you to address some early design and modeling experiences with your domain experts. The model will require ongoing refinement, so don't think that the spike is going to address all of the needs. It definitely won't and your model will need to be refined over time. I also think that you will face modeling debt. When will you face modeling debt? Likely because you are timeboxed, you will have some dissatisfaction and late learning and a result of experimentation and a desire to make your model better which will cause you to want to refactor the model. But, because you're timeboxed, the modeling efforts will lead to some unfinished modeling during each timebox such as a sprint or an iteration. These will naturally lead to incurring modeling debt where you will want your domain model to be refined in a later sprint or a later iteration if you're using Kanban. So the modeling debt must be paid at some point in the future because you don't have time to do it now. Don't ignore this. Take the opportunity to call out the modeling debt and address it in a later sprint or iteration.

Now we want to find the necessary tasks to work on and how we can estimate the level of effort needed for each of the tasks. Did you realize as we were going through the event storming session that at some point when you are actually identifying implementation level detail as part of your event storming effort, you can actually come up with estimation units? For example, we've identified the aggregates involved to some level of implementation detail. We've also identified the commands and the events that get emitted by the aggregate. So naturally, these each can become an estimation unit. Given our estimation units such as here AdCredits as an aggregate, Consume Credit as a command and AdCredit Consumed as an event, for example, or AdSpot aggregate with DefineAdSpot and AdSpotDefined domain event, leads us to an understanding that we have some estimation units. We can now create a simple table. This table has a heading of Component Type followed by an Easy column, a Moderate column and a Complex column. This represents a number of hours or a fraction of hours. For example, a domain event that is easy to implement, may require just 1/10 of one hour or about six minutes to implement. A moderately complex domain event may take 2/10 of an hour or about 12 minutes to implement. And a complex domain event may take 3/10 of an hour. I think you get the idea. We can create a row for commands, a row for aggregates. This can extend to any other kind of artifact type or component type such as domain services, views, process managers. Whatever kind of component needs to be defined, we can define a number of hours or a fraction of hours for an easy moderate or complex level of implementation. Now we take each of our estimation units that we saw in the previous slide and estimate each of those. Take the AdCredits aggregate, the Consume Credit command and the AdCredit Consumed event and estimate is this an easy aggregate, an easy command, an easy event? For each of those, log a number of hours or a fraction of hours that are needed and as you estimate each of the aggregates in your event storming session, each of the domain events, each of the commands, each of the processes, each of the views and so on, you will eventually come up with a target estimate for how much time this would take. Now understand that you're not going to be perfect at this metrics based estimation process at first. You're going to have to tune your estimations under the easy, moderate and complex columns as you go along. You may need to add some fractions of time. You may need to add or subtract some fractions of time in order to become more accurate. Also understand that these estimates can include unit tests for each of these. So for example, if you estimate that a complex aggregate requires four hours to implement, four hours would be an inaccurate estimation if it took four hours just to implement the aggregate. If it required another two hours to implement the unit test for the aggregate, for example, then you should estimate the complexity at six hours, not four hours. So just to give you an idea that you can use each of the estimates for each of the component types to include testing or unit tests for each of the types.

Now let's see how we can work with timeboxed modeling. We have our estimates, our estimation units that are derived from the table that you just saw and we're going to set timeboxed modeling now. In the To Do column we have our AdSpot Aggregate. We're saying that it's going to take one hour to implement this AdSpot Aggregate. It's going to take one hour for the commands and one and a half hours for all the events. We also have some sort of payment, which is going to take about 30 minutes to implement. As we timebox these, make sure that we adhere to the timeboxing for each of these. And there's gonna be a bit of a fudge factor in this because it probably won't take a full hour to create the commands and it probably won't take a full hour and a half. So some of the time that is allotted for the AdSpot Commands and AdSpot Events can actually fold in to the AdSpot Aggregate. All together though, the time will probably be fairly accurate. You can see what is In Progress, the Appointment Aggregate, the Appointment Events and the ServiceShop Aggregate are in progress now and you can see what's done. When you find the actual times throughout this timeboxing process, mark down the actual times on the sticky notes. If you overran your time allotted in the timebox, note why it was overrun. Is it because you simply misestimated with less accuracy the complexity level of this particular aggregate? Perhaps you did. If so, you can learn how to better estimate your aggregate complexity over time. So use these estimation units to timebox your modeling and track how you did. Now we're at the point where we need to refine the model. Recall that I said that you will probably not reach the level of implementation detail that you need for full implementation from a series of event storming sessions. So you're still going to need to produce scenarios and acceptance tests. Notice here that, for example, scenario one will cause the creation of some sort of acceptance test, whether it's a unit test or whether you use BDD. So we're going to create a test for Aggregate A. The test for Aggregate A will prove that Aggregate A works according to domain expert information, conversations and experimentation and collaboration. So when we produce the test for Aggregate A, we also produce the actual implementation of Aggregate A. Aggregate A has Command A1 and Event A1. Event A1 causes the eventual update of Aggregate B. Now you could think of Aggregate A as being a backlog item and Aggregate B as being the sprint. Event A1 would be backlog item committed event. Now as test of Aggregate A1 drives out the full behavior of Aggregate A, you're going to learn that Aggregate B or the sprint also needs to be designed. What does this lead to? It leads to the creation of Scenario two. It also leads to the creation of a test for Aggregate B and test for Aggregate B leads to the refinement of Aggregate B. In turn, as you refine Aggregate B and the test for Aggregate B, you're going to learn more about a Scenario #3 and so forth. So you can see how the scenarios leading to unit tests, leading to refinement of the model, plays into quick iterations across the scenarios that help you to understand the full implementation of the model that adheres to the ubiquitous language. The question now is, how much time do you need with domain experts? I must say that in my experience, domain experts time can be quite limited, so you don't want to overuse their time. How can you limit the amount of time and still be effective in your model refinement? Well definitely you need domain expert's time during event storming sessions. I already said that. But those may be treated as spikes from time to time. You also need domain expert's time though when you're defining scenarios that have even more detail for the model. So discussions with domain experts and the creation of model scenarios with the entire team or with at least one or a few developers and a domain expert will be necessary. You will need their time then. For example, the test of aggregate A, you will need domain expert's time to review the test and verify the model's correctness according to the acceptance tests. You must assume that this test to start with adheres to the ubiquitous language and the use of quality test data according to the scenarios that were defined at the outset. Continuing on with this as you develop the model, the actual implementation of aggregate A and Command A1 and the emitted Event A1, you will need time with domain experts to refine the language, the names, the commands, the events, even the test data that are determined with the help of domain experts and the entire team. Ambiguities are resolved through review, questions and further discussion. So all of this takes collaboration, but if you're careful, you can limit the time with domain experts to quality time. Perhaps just a few minutes with each test and the resulting modeling implementation.

In summary, you learned about Event Storming and how it can be used and how to perform sessions with your team all with the view to accelerating your modeling efforts. You learned about other tools that can be used along with Event Storming. You learned how to use DDD on a project and how to manage estimations and the time you need with Domain Experts, all fitting into an agile project management framework.

